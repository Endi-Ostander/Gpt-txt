#project_root\config.py пуст

#project_root\README.md пуст

#project_root\requirements.txt
pytest

#project_root\run
from core.learner.trainer import Trainer

def main():
   trainer = Trainer()
    print("Введите текст для обучения ИИ (exit — выход):")
    while True:
        user_input = input("> ")
        if user_input.lower() == "exit":
           break
        trainer.process_text(user_input)

if __name__ == "__main__":
    main()

#project_root\core\common\log.py
import logging
import os

LOG_DIR = "data/logs"
os.makedirs(LOG_DIR, exist_ok=True)

logging.basicConfig(
    filename=os.path.join(LOG_DIR, "ai.log"),
    filemode='a',
    format='%(asctime)s | %(levelname)s | %(message)s',
    level=logging.DEBUG
)

def log_info(message: str):
    logging.info(message)

def log_error(message: str):
    logging.error(message)

def log_debug(message: str):
    logging.debug(message)

#project_root\core\common\types
from dataclasses import dataclass
from enum import Enum
from typing import List, Dict, Any, Optional


class PhraseType(Enum):
    """Типы фраз, которые может обрабатывать ИИ."""
    STATEMENT = "statement"    # Утверждение
    QUESTION = "question"      # Вопрос
    COMMAND = "command"        # Команда
    UNKNOWN = "unknown"        # Неопределено


class KnowledgeType(Enum):
    """Типы знаний, сохраняемых в память."""
    FACT = "fact"
    CONCEPT = "concept"
    DEFINITION = "definition"
    RULE = "rule"
    EVENT = "event"


@dataclass
class Phrase:
    """Структура входной фразы."""
    text: str
    tokens: List[str]
    phrase_type: PhraseType
    intent: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None


@dataclass
class Fact:
    """Факт, который можно сохранить в память."""
    id: str
    subject: str
    predicate: str
    obj: str
    source: Optional[str]
    timestamp: str


@dataclass
class KnowledgeEntry:
    """Хранилище произвольной информации."""
    id: str
    title: str
    content: str
    type: KnowledgeType
    tags: List[str]
    created: str
#project_root\core\common\utils.py

import json
import os
import re
import uuid
from datetime import datetime, timezone

def clean_text(text: str) -> str:
    """Удаляет лишние пробелы, спецсимволы и приводит к нижнему регистру."""
    text = re.sub(r'[^\w\s]', '', text)  # Удалить пунктуацию
    return re.sub(r'\s+', ' ', text).strip().lower()

def normalize_whitespace(text: str) -> str:
    """Приводит все пробелы к одному."""
    return re.sub(r'\s+', ' ', text).strip()

def generate_id() -> str:
    """Создаёт уникальный идентификатор."""
    return str(uuid.uuid4())

def timestamp() -> str:
    """Возвращает текущую дату и время в ISO формате."""
    return datetime.now(timezone.utc).isoformat()

def load_json(filepath: str) -> dict:
    """Загружает JSON-файл в словарь."""
    if not os.path.exists(filepath):
        return {}
    with open(filepath, 'r', encoding='utf-8') as f:
        return json.load(f)

def save_json(filepath: str, data: dict) -> None:
    """Сохраняет словарь в JSON-файл."""
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=4, ensure_ascii=False)

def pretty_print(obj):
    """Удобный вывод словаря."""
    print(json.dumps(obj, indent=4, ensure_ascii=False))

#project_root\core\inputs\html_scraper.py
import requests
from bs4 import BeautifulSoup

class HtmlScraper:
    """
    Модуль для сбора текстов с HTML-страниц.
    Минимальная реализация для извлечения текста из тега <body>.
    """
    def fetch_text(self, url: str) -> str:
        try:
            response = requests.get(url)
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, "html.parser")
                body = soup.body
                return body.get_text(separator=' ', strip=True) if body else ""
            else:
                print(f"[HtmlScraper] Ошибка загрузки страницы: {response.status_code}")
                return ""
        except Exception as e:
            print(f"[HtmlScraper] Исключение: {e}")
            return ""

#project_root\core\inputs\text_input.py
class TextInput:
    """
    Модуль для получения текстового ввода от пользователя.
    Пока просто заглушка для имитации ввода.
    """
    def get_input(self) -> str:
        return input("Введите текст для ИИ: ")

#project_root\core\learner\curiosity.py
class Curiosity:
    """
    Модуль любознательности — анализирует, когда ИИ не понимает,
    и формирует вопросы для уточнения.
    Пока базовая реализация.
    """
    def __init__(self):
        self.unknown_phrases = []

    def add_unknown(self, phrase: str):
        self.unknown_phrases.append(phrase)
        print(f"[Curiosity] Новая непонятная фраза добавлена: {phrase}")

    def get_questions(self):
        # Возвращает список вопросов для уточнения
        return [f"Что значит: '{p}'?" for p in self.unknown_phrases]

#project_root\core\learner\reinforce.py
class Reinforce:
    """
    Модуль для подкрепления обучения ИИ.
    Пока заглушка — сюда можно добавить логику усиления изученных знаний,
    например, усиление весов правил или фактов по частоте использования.
    """
    def __init__(self):
        self.rewards = {}

    def reinforce_fact(self, fact_id: str):
        self.rewards[fact_id] = self.rewards.get(fact_id, 0) + 1
        print(f"[Reinforce] Усиление факта {fact_id}: {self.rewards[fact_id]}")

    def get_reward(self, fact_id: str) -> int:
        return self.rewards.get(fact_id, 0)

#project_root\core\learner\rules.py
from typing import List, Optional, Dict, Any
from core.common.types import PhraseType

class Rule:
    """
    Правило для интерпретации фразы и преобразования в знание или действие.
    """
    def __init__(self, name: str, condition: callable, action: callable):
        self.name = name
        self.condition = condition  # Функция: принимает (phrase_type, tokens, raw_text), возвращает bool
        self.action = action        # Функция: принимает (phrase_type, tokens, raw_text), возвращает результат


class RulesEngine:
    def __init__(self):
        self.rules: List[Rule] = []

    def add_rule(self, rule: Rule):
        self.rules.append(rule)

    def apply_rules(self, phrase_type: PhraseType, tokens: List[str], raw_text: str) -> Optional[Dict[str, Any]]:
        """
        Применяет правила к фразе. Возвращает результат первого применимого правила.
        """
        for rule in self.rules:
            if rule.condition(phrase_type, tokens, raw_text):
                return rule.action(phrase_type, tokens, raw_text)
        return None


# Условие и действие для факта с 3 и более токенами
def condition_fact_long(phrase_type: PhraseType, tokens: List[str], raw_text: str) -> bool:
    return phrase_type == PhraseType.STATEMENT and len(tokens) >= 3

def action_fact_long(phrase_type: PhraseType, tokens: List[str], raw_text: str) -> Dict[str, Any]:
    subject = tokens[0]
    predicate = tokens[1]
    obj = " ".join(tokens[2:])
    return {"type": "fact", "subject": subject, "predicate": predicate, "object": obj, "source": raw_text}

# Условие и действие для факта с ровно 2 токенами
def condition_fact_short(phrase_type: PhraseType, tokens: List[str], raw_text: str) -> bool:
    return phrase_type == PhraseType.STATEMENT and len(tokens) == 2

def action_fact_short(phrase_type: PhraseType, tokens: List[str], raw_text: str) -> Dict[str, Any]:
    subject = tokens[0]
    predicate = tokens[1]
    obj = ""  # Объекта нет
    return {"type": "fact", "subject": subject, "predicate": predicate, "object": obj, "source": raw_text}


# Инициализация движка и добавление правил в порядке приоритета
rules_engine = RulesEngine()
rules_engine.add_rule(Rule("fact_rule_long", condition_fact_long, action_fact_long))
rules_engine.add_rule(Rule("fact_rule_short", condition_fact_short, action_fact_short))

#project_root\core\learner\trainer.py
from core.processor.tokenizer import Tokenizer
from core.processor.classifier import Classifier
from core.memory.memory import Memory
from core.common.types import PhraseType
from core.learner.rules import rules_engine


class Trainer:
    def __init__(self):
        self.tokenizer = Tokenizer()
        self.classifier = Classifier()
        self.memory = Memory()

    def process_text(self, text: str):
        """Главная точка обучения: обработка входного текста"""
        phrase_type = self.classifier.classify(text)
        tokens = self.tokenizer.tokenize(text)

        print(f"[Trainer] Тип фразы: {phrase_type.name}")
        print(f"[Trainer] Токены: {tokens}")

        result = rules_engine.apply_rules(phrase_type, tokens, text)
        if result:
            if result.get("type") == "fact":
                added = self.memory.add_fact(
                    result["subject"],
                    result["predicate"],
                    result["object"],
                    source=result.get("source")
                )
                if added:
                    print(f"[Trainer] Запомнено: {result['subject']} — {result['predicate']} — {result['object']}")
            else:
                # Можно расширить обработку для других типов правил здесь
                print(f"[Trainer] Обработано правило типа: {result.get('type')}")
        else:
            print("[Trainer] Правила не применимы к данной фразе.")

#project_root\core\memory\updata.py
from core.memory.memory import Memory
from core.common.types import Fact

class UpdateMemory:
    """
    Модуль обновления существующих фактов в памяти.
    Пока реализована простая замена факта по ID.
    """
    def __init__(self):
        self.memory = Memory()

    def update_fact(self, fact_id: str, new_subject: str, new_predicate: str, new_obj: str):
        updated = False
        for i, fact in enumerate(self.memory.facts):
            if fact.id == fact_id:
                self.memory.facts[i] = Fact(fact_id, new_subject, new_predicate, new_obj, fact.source, fact.timestamp)
                updated = True
                break
        if updated:
            self.memory._save_facts()
            print(f"[UpdateMemory] Факт {fact_id} обновлен.")
        else:
            print(f"[UpdateMemory] Факт {fact_id} не найден.")

#project_root\core\memory\recall.py
from core.memory.memory import Memory

class Recall:
    """
    Модуль для извлечения и поиска информации из памяти.
    Делегирует функции объекту Memory.
    """
    def __init__(self):
        self.memory = Memory()

    def recall_facts(self, subject: str):
        return self.memory.find_facts_by_subject(subject)

    def recall_knowledge(self, tag: str):
        return self.memory.find_knowledge_by_tag(tag)

#project_root\core\memory\memory.py
import os
from typing import List, Optional
from core.common.utils import load_json, save_json, generate_id, timestamp
from core.common.types import Fact, KnowledgeEntry, KnowledgeType

MEMORY_FILE = "data/memory.json"
KNOWLEDGE_FILE = "data/knowledge_base.json"


class Memory:
    def __init__(self, memory_path: Optional[str] = None, knowledge_path: Optional[str] = None):
        self.memory_path = memory_path or MEMORY_FILE
        self.knowledge_path = knowledge_path or KNOWLEDGE_FILE

        self.facts = self._load_facts()
        self.knowledge = self._load_knowledge()

    def _load_facts(self) -> List[Fact]:
        if not os.path.exists(self.memory_path):
            # Если файл не существует, возвращаем пустой список
            return []
        
        data = load_json(self.memory_path)
        return [Fact(**f) for f in data.get("facts", [])]

    def _load_knowledge(self) -> List[KnowledgeEntry]:
        if not os.path.exists(self.knowledge_path):
            # Если файл не существует, возвращаем пустой список
            return []
        
        data = load_json(self.knowledge_path)
        return [KnowledgeEntry(**k) for k in data.get("entries", [])]

    def _save_facts(self):
        data = {"facts": [f.__dict__ for f in self.facts]}
        save_json(self.memory_path, data)

    def _save_knowledge(self):
        data = {
            "entries": [
                {
                    **k.__dict__,
                    "type": k.type.value if hasattr(k.type, "value") else k.type
                }
                for k in self.knowledge
            ]
        }
        save_json(self.knowledge_path, data)

    def add_fact(self, subject: str, predicate: str, obj: str, source: Optional[str] = None) -> bool:
        for f in self.facts:
            if f.subject == subject and f.predicate == predicate and f.obj == obj:
                print(f"[Memory] Факт уже существует: {subject} — {predicate} — {obj}")
                return False

        fact = Fact(
            id=generate_id(),
            subject=subject,
            predicate=predicate,
            obj=obj,
            source=source,
            timestamp=timestamp()
        )
        self.facts.append(fact)
        self._save_facts()
        print(f"[Memory] Новый факт добавлен: {subject} — {predicate} — {obj}")
        return True

    def add_knowledge(self, title: str, content: str, k_type: KnowledgeType, tags: List[str]):
        entry = KnowledgeEntry(
            id=generate_id(),
            title=title,
            content=content,
            type=k_type,
            tags=tags,
            created=timestamp()
        )
        self.knowledge.append(entry)
        self._save_knowledge()

    def find_facts_by_subject(self, subject: str) -> List[Fact]:
        return [f for f in self.facts if f.subject == subject]

    def find_knowledge_by_tag(self, tag: str) -> List[KnowledgeEntry]:
        return [k for k in self.knowledge if tag in k.tags]

#project_root\core\processor\classifier.py
from core.common.types import PhraseType


class Classifier:
    def __init__(self):
        self.question_starters = {"что", "кто", "где", "почему", "зачем", "как", "когда", "сколько", "можно", "ли"}
        self.command_verbs = {"расскажи", "покажи", "скажи", "объясни", "запомни", "ответь", "найди"}

    def classify(self, text: str) -> PhraseType:
        lowered = text.strip().lower()

        if all(c == '?' for c in lowered):
            return PhraseType.UNKNOWN

        if lowered.endswith("?"):
            return PhraseType.QUESTION

        if any(lowered.startswith(q) for q in self.question_starters):
            return PhraseType.QUESTION

        if any(lowered.startswith(cmd) for cmd in self.command_verbs):
            return PhraseType.COMMAND

        if lowered.endswith(".") or " " in lowered:
            return PhraseType.STATEMENT

        return PhraseType.UNKNOWN

#project_root\core\processor\extractor.py
from typing import Dict, Any, Optional

class Extractor:
    """
    Модуль для извлечения информации из токенов и текста.
    На этом этапе — простой интерфейс.
    """
    def extract_fact(self, tokens: list, raw_text: str) -> Optional[Dict[str, Any]]:
        if len(tokens) < 3:
            return None
        return {
            "subject": tokens[0],
            "predicate": tokens[1],
            "object": " ".join(tokens[2:]),
            "source": raw_text
        }

#project_root\core\processor\parser.py
from typing import List
from core.common.types import Phrase

class Parser:
    """
    Модуль разбора фразы на составные части.
    Пока простая заглушка — возвращает исходный текст как фразу с пустыми токенами.
    Позже можно добавить синтаксический разбор.
    """
    def parse(self, text: str) -> Phrase:
        return Phrase(text=text, tokens=text.split(), phrase_type=None)

#project_root\core\processor\tokenizer.py
import re
from typing import List
from core.common.utils import clean_text


class Tokenizer:
    def __init__(self):
        # Можно позже добавить список стоп-слов
        self.delimiters = r"[ \t\n\r\f\v.,!?;:\"()\-—]+"  # Разделители слов

    def tokenize(self, text: str) -> List[str]:
        """Разбивает строку на токены."""
        cleaned = clean_text(text)
        tokens = re.split(self.delimiters, cleaned)
        return [t for t in tokens if t]  # Убираем пустые строки

    def count_tokens(self, text: str) -> int:
        """Подсчитывает количество токенов."""
        return len(self.tokenize(text))

    def preview_tokens(self, text: str) -> None:
        """Выводит токены в консоль для отладки."""
        tokens = self.tokenize(text)
        print(f"[Tokenizer] → {tokens}")

#project_root\tests\__init.py пуст

#project_root\tests\test_classifier.py
import pytest
from core.processor.classifier import Classifier
from core.common.types import PhraseType

classifier = Classifier()

@pytest.mark.parametrize("text,expected", [
    ("Что ты знаешь?", PhraseType.QUESTION),
    ("Сколько времени?", PhraseType.QUESTION),
    ("Расскажи про солнце", PhraseType.COMMAND),
    ("Солнце — это звезда.", PhraseType.STATEMENT),
    ("???", PhraseType.UNKNOWN),
])
def test_classify(text, expected):
    assert classifier.classify(text) == expected

#project_root\tests\test_memory.py
import tempfile
import shutil
import os
from core.memory.memory import Memory
from core.common.types import KnowledgeType

def test_memory_fact_storage():
    tmp_dir = tempfile.mkdtemp()
    memory_file = os.path.join(tmp_dir, "memory.json")
    knowledge_file = os.path.join(tmp_dir, "knowledge_base.json")

    # Создаём пустые файлы для памяти
    with open(memory_file, "w", encoding="utf-8") as f:
        f.write('{"facts": []}')
    with open(knowledge_file, "w", encoding="utf-8") as f:
        f.write('{"entries": []}')

    # Переопределяем пути
    memory = Memory(memory_path=memory_file, knowledge_path=knowledge_file)

    # Добавляем факт
    memory.add_fact("Тест", "есть", "данные", "тест")
    
    # Проверяем, что факт был добавлен
    facts = memory.find_facts_by_subject("Тест")
    assert len(facts) == 1
    assert facts[0].predicate == "есть"

    shutil.rmtree(tmp_dir)

def test_memory_knowledge_storage():
    tmp_dir = tempfile.mkdtemp()
    memory_file = os.path.join(tmp_dir, "memory.json")
    knowledge_file = os.path.join(tmp_dir, "knowledge_base.json")

    # Очистка временных файлов
    with open(memory_file, "w", encoding="utf-8") as f:
        f.write('{"facts": []}')
    with open(knowledge_file, "w", encoding="utf-8") as f:
        f.write('{"entries": []}')

    # Переопределяем пути
    memory = Memory(memory_path=memory_file, knowledge_path=knowledge_file)

    # Добавляем знания
    memory.add_knowledge("Тест", "Описание", KnowledgeType.FACT, ["тест"])
    
    # Проверяем, что знания добавлены
    found = memory.find_knowledge_by_tag("тест")
    assert len(found) == 1

    shutil.rmtree(tmp_dir)

#project_root\tests\test_tokenizer.py
import pytest
from core.processor.tokenizer import Tokenizer

tokenizer = Tokenizer()

def test_tokenize_basic():
    text = "Привет, мир!"
    tokens = tokenizer.tokenize(text)
    assert tokens == ["привет", "мир"]

def test_tokenize_empty():
    assert tokenizer.tokenize("") == []

def test_tokenize_whitespace():
    assert tokenizer.tokenize("   \n\t") == []

#project_root\data\knowledge_base.json работает

#project_root\data\memory.json работает

#project_root\data\logs пуст

#project_root\tools\devconsole_ext.py
import sys
import os
import csv
import subprocess

# Добавляем корень проекта в sys.path для корректных импортов
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from core.memory.memory import Memory
from core.processor.tokenizer import Tokenizer
from core.processor.classifier import Classifier
from core.common.types import KnowledgeType

def resource_path(relative_path):
    """Получить абсолютный путь к ресурсу, относительно папки скрипта."""
    return os.path.abspath(os.path.join(os.path.dirname(__file__), relative_path))

# Инициализация
memory = Memory(
    memory_path=resource_path("../data/memory.json"),
    knowledge_path=resource_path("../data/knowledge_base.json")
)

tokenizer = Tokenizer()
classifier = Classifier()

HELP = """
🧪 Расширенная Dev Console — команды:

  Общие:
    help                 — показать этот справочник
    exit                 — выйти из консоли
    run                  — запустить run.py

  Просмотр и поиск:
    mem facts            — вывести все факты
    mem facts <слово>    — вывести факты по субъекту <слово>
    mem knowledge        — вывести все знания
    mem knowledge <тег>  — вывести знания по тегу <тег>

  Работа с памятью:
    add fact <subj> <pred> <obj> [source]   — добавить факт
    del fact <id>                           — удалить факт по id

  Экспорт:
    mem export md        — экспорт памяти в Markdown (memory_report.md)
    mem export csv       — экспорт памяти в CSV (memory_report.csv)

  Тестирование:
    test <фраза>        — токенизация и классификация

  Пример:
    add fact солнце есть звезда Википедия
"""

def print_facts(filter_subj=None):
    filtered = memory.facts
    if filter_subj:
        filtered = [f for f in filtered if filter_subj.lower() in f.subject.lower()]
    if not filtered:
        print("❌ Факты не найдены.")
        return
    for f in filtered:
        print(f"- ID:{f.id} | {f.subject} — {f.predicate} — {f.obj} | from: {f.source or 'n/a'}")

def print_knowledge(filter_tag=None):
    filtered = memory.knowledge
    if filter_tag:
        filtered = [k for k in filtered if filter_tag.lower() in map(str.lower, k.tags)]
    if not filtered:
        print("❌ Знания не найдены.")
        return
    for k in filtered:
        print(f"- ID:{k.id} | {k.title} [{k.type.value}] — {', '.join(k.tags)}")
        print(f"  > {k.content}")

def export_md():
    with open("memory_report.md", "w", encoding="utf-8") as f:
        f.write("# 🧠 Память ИИ\n\n## 📌 Факты\n\n")
        for fact in memory.facts:
            f.write(f"- **{fact.subject}** — *{fact.predicate}* — {fact.obj}\n")
            f.write(f"  Источник: `{fact.source}`\n")
            f.write(f"  Время: `{fact.timestamp}`\n\n")
        f.write("## 📚 Знания\n\n")
        for entry in memory.knowledge:
            f.write(f"- **{entry.title}** ({entry.type.value})\n")
            f.write(f"  > {entry.content}\n")
            f.write(f"  Теги: {', '.join(entry.tags)}\n")
            f.write(f"  Время: `{entry.created}`\n\n")
    print("✅ Отчёт сохранён в memory_report.md")

def export_csv():
    with open("memory_report.csv", "w", encoding="utf-8", newline='') as f:
        writer = csv.writer(f)
        writer.writerow(["Type", "ID", "Subject/Title", "Predicate", "Object/Content", "Source/Tags", "Timestamp/Created"])
        for fact in memory.facts:
            writer.writerow(["Fact", fact.id, fact.subject, fact.predicate, fact.obj, fact.source or "", fact.timestamp])
        for entry in memory.knowledge:
            tags = ";".join(entry.tags)
            writer.writerow(["Knowledge", entry.id, entry.title, "", entry.content, tags, entry.created])
    print("✅ Отчёт сохранён в memory_report.csv")

def add_fact(args):
    if len(args) < 3:
        print("⚠️ Нужно минимум 3 аргумента: subject predicate object [source]")
        return
    subject = args[0]
    predicate = args[1]
    rest = args[2:]
    obj = " ".join(rest[:-1]) if len(rest) > 1 else rest[0]
    source = rest[-1] if len(rest) > 1 else None
    memory.add_fact(subject, predicate, obj, source)
    print(f"✅ Факт добавлен: {subject} — {predicate} — {obj}")

def del_fact(args):
    if len(args) != 1:
        print("⚠️ Нужно указать ID факта для удаления.")
        return
    fid = args[0]
    before = len(memory.facts)
    memory.facts = [f for f in memory.facts if f.id != fid]
    memory._save_facts()
    if len(memory.facts) < before:
        print(f"✅ Факт с ID {fid} удалён.")
    else:
        print(f"❌ Факт с ID {fid} не найден.")

def main():
    print(HELP)
    while True:
        try:
            line = input("> ").strip()
            if not line:
                continue

            if line.lower() == "exit":
                break
            elif line.lower() == "help":
                print(HELP)
                continue
            elif line.lower() == "run":
                # Запускаем run.py из корня проекта (на уровень выше)
                run_path = resource_path("../run.py")
                if os.path.exists(run_path):
                    subprocess.run([sys.executable, run_path])
                else:
                    print(f"⚠️ Файл run.py не найден по пути: {run_path}")
                continue

            parts = line.split()
            cmd = parts[0].lower()

            if cmd == "mem":
                if len(parts) < 2:
                    print("⚠️ Укажите аргумент: facts, knowledge или export")
                    continue
                subcmd = parts[1].lower()
                if subcmd == "facts":
                    subj = parts[2] if len(parts) > 2 else None
                    print_facts(subj)
                elif subcmd == "knowledge":
                    tag = parts[2] if len(parts) > 2 else None
                    print_knowledge(tag)
                elif subcmd == "export":
                    if len(parts) < 3:
                        print("⚠️ Укажите формат экспорта: md или csv")
                    elif parts[2].lower() == "md":
                        export_md()
                    elif parts[2].lower() == "csv":
                        export_csv()
                    else:
                        print("⚠️ Неизвестный формат. Используйте md или csv.")
                else:
                    print("⚠️ Неизвестная команда mem.")
            elif cmd == "add" and len(parts) > 1 and parts[1].lower() == "fact":
                add_fact(parts[2:])
            elif cmd == "del" and len(parts) > 1 and parts[1].lower() == "fact":
                del_fact(parts[2:])
            elif cmd == "test":
                phrase = " ".join(parts[1:])
                tokens = tokenizer.tokenize(phrase)
                p_type = classifier.classify(phrase)
                print(f"[Test] Тип: {p_type.name}")
                print(f"[Test] Токены: {tokens}")
            else:
                phrase = line
                tokens = tokenizer.tokenize(phrase)
                p_type = classifier.classify(phrase)
                print(f"[Debug] Тип: {p_type.name}")
                print(f"[Debug] Токены: {tokens}")
                facts = memory.find_facts_by_subject(tokens[0]) if tokens else []
                if facts:
                    print(f"[Debug] Факты по '{tokens[0]}':")
                    for f in facts:
                        print(f"  - {f.subject} — {f.predicate} — {f.obj}")
                else:
                    print("[Debug] Факты не найдены.")
        except KeyboardInterrupt:
            print("\n🛑 Выход.")
            break
        except Exception as e:
            print(f"⚠️ Ошибка: {e}")

if __name__ == "__main__":
    main()